{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNBoOeg7YW6W7WnecyoLk2B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! git clone https://github.com/WongKinYiu/yolov7.git\n","\n","%cd yolov7"],"metadata":{"id":"ubpwa2quWuES","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668349425658,"user_tz":-480,"elapsed":4028,"user":{"displayName":"Myat Htet Kyaw","userId":"01895056269117193142"}},"outputId":"efcc8295-23dd-4684-b0be-a23c956ea9a6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 998, done.\u001b[K\n","remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 998\u001b[K\n","Receiving objects: 100% (998/998), 69.77 MiB | 30.40 MiB/s, done.\n","Resolving deltas: 100% (465/465), done.\n","/content/yolov7\n","cfg\tdetect.py  hubconf.py  models\t  requirements.txt  tools\t  utils\n","data\texport.py  inference   paper\t  scripts\t    train_aux.py\n","deploy\tfigure\t   LICENSE.md  README.md  test.py\t    train.py\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"cklpeCCQV8AI","executionInfo":{"status":"ok","timestamp":1668350319164,"user_tz":-480,"elapsed":3602,"user":{"displayName":"Myat Htet Kyaw","userId":"01895056269117193142"}},"outputId":"76437285-afc6-470a-9b78-27ac638a339e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import torch\n","from torchvision import transforms\n","from utils.datasets import letterbox\n","from utils.general import non_max_suppression_kpt\n","from utils.plots import output_to_keypoint\n","import pandas as pd\n","import cv2\n","import numpy as np\n","import os\n","import random\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["def load_model():\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model = torch.load('/content/drive/My Drive/mini_project/models/yolov7-w6-pose.pt', map_location=device)['model']\n","    # Put in inference mode\n","    model.float().eval()\n","\n","    if torch.cuda.is_available():\n","        # half() turns predictions into float16 tensors\n","        # which significantly lowers inference time\n","        model.half().to(device)\n","    return model\n","\n","model = load_model()"],"metadata":{"id":"pxvdflZZWb5W","executionInfo":{"status":"ok","timestamp":1668349688177,"user_tz":-480,"elapsed":4511,"user":{"displayName":"Myat Htet Kyaw","userId":"01895056269117193142"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def run_inference(image):\n","    # Resize and pad image\n","    image = letterbox(image, 960, stride=64, auto=True)[0] # shape: (768, 960, 3)\n","    # Apply transforms\n","    image = transforms.ToTensor()(image) # torch.Size([3, 768, 960])\n","    # Turn image into batch\n","    image = image.unsqueeze(0) # torch.Size([1, 3, 768, 960])\n","    output, _ = model(image) # torch.Size([1, 45900, 57])\n","    return output, image\n","def plot_skeleton_kpts(im, kpts, steps, orig_shape=None):\n","    #Plot the skeleton and keypointsfor coco datatset\n","    palette = np.array([[255, 128, 0], [255, 153, 51], [255, 178, 102],\n","                        [230, 230, 0], [255, 153, 255], [153, 204, 255],\n","                        [255, 102, 255], [255, 51, 255], [102, 178, 255],\n","                        [51, 153, 255], [255, 153, 153], [255, 102, 102],\n","                        [255, 51, 51], [153, 255, 153], [102, 255, 102],\n","                        [51, 255, 51], [0, 255, 0], [0, 0, 255], [255, 0, 0],\n","                        [255, 255, 255]])\n","\n","    skeleton = [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12],\n","                [7, 13], [6, 7], [6, 8], [7, 9], [8, 10], [9, 11], [2, 3],\n","                [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]]\n","\n","    pose_limb_color = palette[[9, 9, 9, 9, 7, 7, 7, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 16]]\n","    pose_kpt_color = palette[[16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9]]\n","    radius = 5\n","    num_kpts = len(kpts) // steps\n","    \n","    #store min x, max x, min y, max y\n","    min_x = im.shape[1]\n","    min_y = im.shape[0]\n","    max_x = 0\n","    max_y = 0\n","\n","    for kid in range(num_kpts):\n","        r, g, b = pose_kpt_color[kid]\n","        x_coord, y_coord = kpts[steps * kid], kpts[steps * kid + 1]\n","        if not (x_coord % 640 == 0 or y_coord % 640 == 0):\n","            if steps == 3:\n","                conf = kpts[steps * kid + 2]\n","                if conf < 0.5:\n","                    continue\n","            min_x = min(min_x, x_coord)\n","            min_y = min(min_y, y_coord)\n","            max_x = max(max_x, x_coord)\n","            max_y = max(max_y, y_coord)\n","            cv2.circle(im, (int(x_coord), int(y_coord)), radius, (int(r), int(g), int(b)), -1)\n","            \n","    return [min_x, max_x, min_y, max_y]\n","\n","def visualize_output(output, image):\n","    output = non_max_suppression_kpt(output, \n","                                     0.25, # Confidence Threshold\n","                                     0.65, # IoU Threshold\n","                                     nc=model.yaml['nc'], # Number of Classes\n","                                     nkpt=model.yaml['nkpt'], # Number of Keypoints\n","                                     kpt_label=True)\n","    with torch.no_grad():\n","        output = output_to_keypoint(output)\n","    nimg = image[0].permute(1, 2, 0) * 255\n","    nimg = nimg.cpu().numpy().astype(np.uint8)\n","    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n","    pose = np.full(nimg.shape, 255).astype('uint8')\n","    \n","    for idx in range(output.shape[0]):\n","        x = plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n","        plot_skeleton_kpts(pose, output[idx, 7:].T, 3)\n","    return nimg, pose, x\n"],"metadata":{"id":"llwi5NfxWb77","executionInfo":{"status":"ok","timestamp":1668349692972,"user_tz":-480,"elapsed":305,"user":{"displayName":"Myat Htet Kyaw","userId":"01895056269117193142"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["dir_name = \"/content/drive/My Drive/mini_project/dataset/cleaned\"\n","classes = [\"carrying\", \"threat\", \"normal\"]\n","#labels        0     ,     1   ,     2"],"metadata":{"id":"IKkqOzMIWb-q","executionInfo":{"status":"ok","timestamp":1668350016509,"user_tz":-480,"elapsed":448,"user":{"displayName":"Myat Htet Kyaw","userId":"01895056269117193142"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def transform_data():\n","    c = classes[0]\n","    \n","    dir_path = os.path.join(dir_name, c) # create path\n","    data_ls = os.listdir(dir_path)       # list of file name\n","    count = 0\n","    class_index = classes.index(c)       # class label\n","\n","    # do for 3 classes and range of 500 each. Showing one as example here due to RAM shortage doing all at one go\n","    df = pd.DataFrame(columns=['label','name','points'])\n","\n","    for i in range(1):           \n","        img_name = data_ls[i]       # take item from top of the list\n","        file_path = os.path.join(dir_path, img_name)\n","        print(file_path)\n","        img = cv2.imread(file_path) \n","        output, image = run_inference(img)\n","        img, pose, points = visualize_output(output, image)\n","\n","        print(points)\n","        print(\"done \", count)\n","        count += 1\n","        toSave = {}\n","\n","        # depends on class set above\n","        toSave['label'] = 0\n","\n","        toSave['name'] = img_name\n","\n","        toSave['points'] = points\n","\n","        df = df.append(toSave, ignore_index=True)\n","\n","    df.to_csv('/content/drive/My Drive/mini_project/pose.csv', mode='a', header=False)\n","\n","transform_data()"],"metadata":{"id":"1voI7MosWcCR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668350806887,"user_tz":-480,"elapsed":4206,"user":{"displayName":"Myat Htet Kyaw","userId":"01895056269117193142"}},"outputId":"ae15ef4e-11a9-490a-d96d-093b6a8fbba3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/mini_project/dataset/cleaned/carrying/A0260847X_20220830_threat_00070.38555_30.png\n","[571.3939819335938, 692.4073486328125, 211.8095245361328, 513.035400390625]\n","done  0\n"]}]}]}